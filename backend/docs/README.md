# Backend de Study Tool

[![Node.js](https://img.shields.io/badge/Node.js-v22.15-green)](https://nodejs.org/)
[![Express](https://img.shields.io/badge/Express-4.18-lightgrey)](https://expressjs.com/)
[![Google Gemini](https://img.shields.io/badge/AI-Gemini%201.5%20Pro-blue)](https://ai.google.dev/models/gemini)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue)](https://www.docker.com/)

Este documento proporciona una visi√≥n detallada del backend de la aplicaci√≥n Study Tool, incluyendo su arquitectura, componentes principales, flujo de datos y gu√≠a de configuraci√≥n. Esta versi√≥n utiliza el modelo gemini-1.5-pro de Google, permitiendo el procesamiento multimodal nativo (texto, PDF, im√°genes) y requiere que cada usuario proporcione su propia API Key de Google AI Studio para las operaciones de IA. Para m√°s detalles sobre esta actualizaci√≥n, consulta [MULTIMODAL_UPDATE.md](./MULTIMODAL_UPDATE.md).

## üìù √çndice

- [Arquitectura General](#arquitectura-general)
- [Estructura de Directorios](#estructura-de-directorios)
- [Flujo de Datos](#flujo-de-datos)
- [Endpoints API](#endpoints-api)
- [Integraci√≥n con Google Gemini](#integraci√≥n-con-google-gemini)
- [Configuraci√≥n de Desarrollo](#configuraci√≥n-de-desarrollo)
- [Despliegue](#despliegue)
- [Variables de Entorno](#variables-de-entorno)
- [Escalabilidad y Rendimiento](#escalabilidad-y-rendimiento)
- [Seguridad](#seguridad)

## üèóÔ∏è Arquitectura General

El backend de Study Tool est√° construido utilizando Node.js y Express, siguiendo una arquitectura MVC (Modelo-Vista-Controlador) adaptada, donde:

- **Controladores**: Manejan las solicitudes HTTP y coordinan la l√≥gica de negocio
- **Servicios**: Encapsulan la l√≥gica de integraci√≥n con APIs externas (Gemini AI)
- **Configuraci√≥n**: Almacena prompts y par√°metros para las interacciones con la IA

### Diagrama de Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ‚îÇ         ‚îÇ                    ‚îÇ
‚îÇ    Express App     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ    Controllers     ‚îÇ
‚îÇ                    ‚îÇ         ‚îÇ                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                         ‚îÇ
                                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                    ‚îÇ
‚îÇ   Gemini Client    ‚îÇ         ‚îÇ     Services       ‚îÇ
‚îÇ                    ‚îÇ         ‚îÇ                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÇ Estructura de Directorios

```
backend/
  ‚îú‚îÄ‚îÄ src/                    # C√≥digo fuente principal
  ‚îÇ   ‚îú‚îÄ‚îÄ app.js              # Punto de entrada - configuraci√≥n de Express
  ‚îÇ   ‚îú‚îÄ‚îÄ config/             # Configuraciones y prompts para la IA
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompts.js      # Instrucciones espec√≠ficas para Gemini AI
  ‚îÇ   ‚îú‚îÄ‚îÄ controllers/        # Controladores de las rutas
  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summaryController.js    # Generaci√≥n de res√∫menes en formato Notion
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ flashcardsController.js # Generaci√≥n de tarjetas de estudio
  ‚îÇ   ‚îî‚îÄ‚îÄ services/
  ‚îÇ       ‚îú‚îÄ‚îÄ geminiClient.js  # Cliente para la API de Google Gemini
  ‚îÇ       ‚îî‚îÄ‚îÄ sessionManager.js # Gesti√≥n de sesiones para el procesamiento
  ‚îú‚îÄ‚îÄ docs/                   # Documentaci√≥n adicional
  ‚îú‚îÄ‚îÄ Dockerfile              # Configuraci√≥n para contenedores de producci√≥n
  ‚îú‚îÄ‚îÄ Dockerfile.dev          # Configuraci√≥n para contenedores de desarrollo
  ‚îî‚îÄ‚îÄ package.json            # Dependencias y scripts
```

## üîÑ Flujo de Datos

1. El cliente env√≠a solicitudes HTTP POST a uno de los endpoints:
   - `/summary`: Para transformar texto en formato markdown de Notion
   - `/flashcards`: Para generar tarjetas de estudio en formato TSV

2. Los controladores reciben las solicitudes, procesan los datos de entrada y preparan el contexto para la IA

3. Los servicios env√≠an solicitudes a la API de Google Gemini utilizando el prompt adecuado

4. La respuesta de la IA es procesada y devuelta al frontend en formato JSON

### Diagrama de Secuencia

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          ‚îÇ               ‚îÇ          ‚îÇ          ‚îÇ           ‚îÇ              ‚îÇ          ‚îÇ
‚îÇ Frontend ‚îÇ‚îÄ‚îÄ‚îÄRequest‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇController‚îÇ‚îÄ‚îÄData‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Service  ‚îÇ‚îÄ‚îÄAPI Call‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Gemini   ‚îÇ
‚îÇ          ‚îÇ               ‚îÇ          ‚îÇ          ‚îÇ           ‚îÇ              ‚îÇ    AI    ‚îÇ
‚îÇ          ‚îÇ‚óÑ‚îÄ‚îÄResponse‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ          ‚îÇ‚óÑ‚îÄData‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ           ‚îÇ‚óÑ‚îÄ‚îÄResponse‚îÄ‚îÄ‚îÄ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîå Endpoints API

### POST /summary

Transforma texto en un resumen estructurado con formato Markdown para Notion.

**Request:**
```json
{
  "filesText": "Contenido del documento o texto a procesar"
}
```

**Response:**
```json
{
  "notionMarkdown": "# T√≠tulo del resumen generado\n\n## Secci√≥n 1\n...",
  "stats": {
    "generationTimeMs": 3245,
    "promptTokens": 1520,
    "completionTokens": 2340,
    "totalTokens": 3860
  }
}
```

### POST /summary/condense

Permite condensar o refinar un resumen existente.

**Request:**
```json
{
  "markdownContent": "# Contenido markdown existente",
  "condensationType": "shorter" // Opciones: "shorter", "clarity", "examples"
}
```

**Response:**
```json
{
  "notionMarkdown": "# Resumen condensado\n\n...",
  "stats": {
    "generationTimeMs": 2140,
    "promptTokens": 1820,
    "completionTokens": 1240,
    "totalTokens": 3060
  }
}
```

### POST /flashcards

Genera tarjetas de estudio en formato TSV compatible con Quizlet.

**Request:**
```json
{
  "markdownContent": "# Contenido en formato markdown\n\n## Temas principales\n..."
}
```

**Response:**
```json
{
  "flashcards": "Pregunta 1\tRespuesta 1\nPregunta 2\tRespuesta 2",
  "stats": {
    "generationTimeMs": 2145,
    "promptTokens": 1320,
    "completionTokens": 1140,
    "totalTokens": 2460
  }
}
```

### GET /health

Endpoint para verificar el estado del servidor.

**Response:**
```json
{
  "status": "ok",
  "message": "Server is running"
}
```

## ü§ñ Integraci√≥n con Google Gemini 1.5 Pro

### Configuraci√≥n del Cliente Multimodal

El servicio `geminiClient.js` encapsula toda la comunicaci√≥n con la API de Google Gemini, utilizando la API Key proporcionada por el usuario:

```javascript
// Ejemplo simplificado del cliente multimodal de Gemini
import { GoogleGenerativeAI } from "@google/generative-ai";

// Convierte un buffer de archivo en una parte para la API
function fileToGenerativePart(buffer, mimeType) {
  return {
    inlineData: {
      data: buffer.toString("base64"),
      mimeType,
    },
  };
}

// Genera contenido multimodal usando la API Key del usuario
async function generateMultimodalContent(userApiKey, parts, systemInstructionText) {
  try {
    const genAI = new GoogleGenerativeAI(userApiKey);
    const model = genAI.getGenerativeModel({
      model: "gemini-1.5-pro-latest",
      systemInstruction: systemInstructionText ? { parts: [{ text: systemInstructionText }] } : undefined,
      generationConfig: {
        temperature: 0.3,
        topP: 0.8,
        topK: 40
      }
    });

    const contentsForApi = [{ role: 'user', parts }];
    const result = await model.generateContent({ contents: contentsForApi });
    const response = result.response;
    
    // Procesar y devolver respuesta
    // ...
  } catch (error) {
    // Manejar errores espec√≠ficos (API Key inv√°lida, cuota excedida, etc.)
    // ...
  }
}
```

### Capacidades Multimodales

El backend ahora puede procesar:

- **Texto**: An√°lisis sem√°ntico avanzado
- **PDFs**: Extracci√≥n y comprensi√≥n del contenido completo
- **Im√°genes**: An√°lisis visual y extracci√≥n de informaci√≥n

Gemini 1.5 Pro soporta un gran contexto (hasta 2 millones de tokens), permitiendo analizar documentos extensos y m√∫ltiples im√°genes en una sola solicitud.

### Prompts y Configuraci√≥n

Los prompts para la IA est√°n centralizados en el archivo `prompts.js`, optimizados para contenido multimodal:

- Instrucciones detalladas para formatear res√∫menes en estilo Notion, incluyendo an√°lisis de contenido visual
- Plantillas para la creaci√≥n de tarjetas de estudio basadas en cualquier tipo de contenido
- Ajustes de configuraci√≥n para optimizar la calidad de las respuestas

## ‚öôÔ∏è Configuraci√≥n de Desarrollo

### Requisitos Previos

- Node.js v22.15.0 o superior
- Clave de API de Google Gemini
- Docker (opcional)

### Instalaci√≥n Local

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/study.git
cd study/backend

# Instalar dependencias
npm install

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tu API key de Google Gemini

# Iniciar en modo desarrollo
npm run dev
```

### Desarrollo con Docker

```bash
# Construir y ejecutar con Docker
docker build -t study-tool-backend -f Dockerfile.dev .
docker run -p 4000:4000 -v $(pwd):/app --env-file .env study-tool-backend
```

## üöÄ Despliegue

### Con Docker Swarm

```bash
# Crear secretos necesarios
echo "tu_gemini_api_key" | docker secret create gemini_api_key -

# Desplegar el stack completo
docker stack deploy --with-registry-auth -c docker-stack.yml study-tool
```

### Despliegue Manual

```bash
# Construir para producci√≥n
docker build -t study-tool-backend:latest .

# Ejecutar en producci√≥n
docker run -d -p 4000:4000 --name study-backend \
  --env GEMINI_API_KEY=tu_api_key \
  --env NODE_ENV=production \
  study-tool-backend:latest
```

## üîê Variables de Entorno

| Variable | Descripci√≥n | Valores por Defecto |
|----------|-------------|---------------------|
| `PORT` | Puerto en que se ejecutar√° el servidor | `4000` |
| `HOST` | Interfaz de red a utilizar | `0.0.0.0` |
| `NODE_ENV` | Entorno de ejecuci√≥n | `development` |
| `GEMINI_API_KEY` | (Opcional) Clave de API para Google Gemini para compatibilidad con versiones anteriores | No requerida |

> **Importante:** A partir de esta actualizaci√≥n, la variable de entorno `GEMINI_API_KEY` ya no es necesaria para la operaci√≥n normal. Cada usuario proporciona su propia API Key a trav√©s del frontend. La variable puede mantenerse para compatibilidad con c√≥digo existente.

## üìà Escalabilidad y Rendimiento

- **Contenedores**: La arquitectura basada en Docker permite escalar horizontalmente seg√∫n la demanda
- **Cach√©**: Implementaci√≥n de estrategias de cach√© para prompts frecuentes
- **Rate Limiting**: Control de tasa de solicitudes para proteger contra sobrecarga
- **Timeout Handling**: Gesti√≥n adecuada de tiempos de espera en solicitudes a la API de Gemini

## üîí Seguridad

- **API Key del Usuario**: Las claves API nunca se almacenan en el backend; se usan s√≥lo para la petici√≥n inmediata
- **Validaci√≥n de Entrada**: Todos los datos de entrada son validados rigurosamente
- **CORS Configurado**: Protecci√≥n contra solicitudes no autorizadas
- **Sin Almacenamiento**: No se almacenan datos de usuario permanentemente
- **L√≠mites de Tama√±o**: Restricciones en el tama√±o m√°ximo de solicitudes (20MB para archivos)
- **Validaci√≥n de Tipos de Archivo**: Solo se permiten PDFs e im√°genes en formatos espec√≠ficos

---

## üìö Referencias y Recursos Adicionales

- [Documentaci√≥n de la API de Gemini](https://ai.google.dev/docs)
- [Mejores pr√°cticas para prompts de IA](https://ai.google.dev/docs/prompting)
- [Express.js Best Practices](https://expressjs.com/en/advanced/best-practice-performance.html)
- [Documentaci√≥n de Docker Swarm](https://docs.docker.com/engine/swarm/)

---

Desarrollado con ‚ù§Ô∏è para potenciar el aprendizaje de los estudiantes

## Integraci√≥n con Google Gemini AI

El backend utiliza la API de Google Gemini para procesar documentos y generar contenido estructurado. Esta integraci√≥n se realiza a trav√©s del m√≥dulo `geminiClient.js`.

### Estrategia de Prompts

Los prompts son cruciales para obtener resultados de alta calidad. El archivo `prompts.js` contiene instrucciones detalladas para:

1. **Generaci√≥n de res√∫menes**: Instrucciones para formatear el contenido siguiendo el estilo de Notion con:
   - Secciones jer√°rquicas con emojis
   - Formato Cornell Notes para facilitar el estudio
   - Destacado de conceptos clave
   - Bloques Toggle para contenido expandible
   - Divisi√≥n del contenido en partes para mejor gesti√≥n

2. **Generaci√≥n de flashcards**: Instrucciones para crear tarjetas de estudio efectivas:
   - Detecci√≥n autom√°tica de idioma para mantener consistencia
   - Formato Quizlet-compatible (TSV)
   - Estructura pregunta-respuesta optimizada para memorizaci√≥n
   - Resaltado de t√©rminos importantes

## Gesti√≥n de Errores

El backend implementa un sistema de manejo de errores en m√∫ltiples niveles:

1. **Validaci√≥n de entrada**: Verifica que se proporcione el contenido necesario
2. **Manejo de l√≠mites**: Control del tama√±o de texto enviado a la API de Gemini
3. **Captura de errores API**: Manejo espec√≠fico de errores en la comunicaci√≥n con Gemini
4. **Middleware global**: Captura errores no manejados y evita interrupciones del servicio

## Configuraci√≥n y Despliegue

### Variables de Entorno

El backend requiere las siguientes variables de entorno:

| Variable | Descripci√≥n | Valor por defecto |
|----------|-------------|-------------------|
| `PORT` | Puerto donde se ejecuta el servidor | 4000 |
| `GEMINI_API_KEY` | Clave de API para Google Gemini | - |
| `NODE_ENV` | Entorno de ejecuci√≥n | development |

### Desarrollo Local

1. Instalar dependencias:
```bash
npm install
```

2. Crear archivo `.env` con la clave de API:
```
GEMINI_API_KEY=your_key_here
PORT=4000
```

3. Iniciar el servidor en modo desarrollo:
```bash
npm run dev
```

### Despliegue con Docker

El backend incluye un Dockerfile optimizado para producci√≥n:

```dockerfile
FROM node:18-alpine

WORKDIR /app

# Instalar dependencias
COPY package*.json ./
RUN npm ci --only=production

# Copiar c√≥digo fuente
COPY . .

# Configurar variables de entorno
ENV NODE_ENV=production
ENV PORT=4000

# Exponer puerto
EXPOSE 4000

# Iniciar aplicaci√≥n
CMD ["node", "src/app.js"]
```

## M√©tricas y Monitoreo

El backend proporciona m√©tricas de uso sobre las solicitudes a la API de Gemini:

- Tiempo de generaci√≥n de contenido
- Recuento de tokens (prompt, respuesta y total)
- Estado de la API (a trav√©s del endpoint `/health`)

## Escalabilidad y Optimizaci√≥n

El backend est√° dise√±ado considerando:

1. **Gesti√≥n de carga**: Manejo de documentos grandes mediante truncamiento inteligente
2. **Eficiencia de tokens**: Prompts optimizados para reducir costos de API
3. **Middleware ligero**: Configuraci√≥n minimalista para reducir overhead

## Consideraciones de Seguridad

1. **CORS**: Configuraci√≥n adecuada para permitir solicitudes desde el frontend
2. **Validaci√≥n de entrada**: Prevenci√≥n de inyecci√≥n de contenido malicioso
3. **Variables de entorno**: Gesti√≥n segura de claves API
4. **Limitaci√≥n de tama√±o**: Control en la recepci√≥n de datos (`limit: '50mb'`)

## Instrucciones para Desarrolladores

### A√±adir Nuevos Endpoints

1. Crear un nuevo controlador en `/src/controllers/`
2. Implementar la l√≥gica de procesamiento
3. Configurar la ruta en `app.js`

### Modificar Prompts

Los prompts pueden ajustarse en `/src/config/prompts.js` para mejorar la calidad del contenido generado:

1. Mantener las instrucciones de formato claramente definidas
2. Utilizar ejemplos espec√≠ficos para guiar a la IA
3. Estructurar las instrucciones en secciones l√≥gicas

## Resoluci√≥n de Problemas

| Problema | Posible causa | Soluci√≥n |
|----------|---------------|----------|
| Error 500 en generaci√≥n de contenido | Fallo en API de Gemini | Verificar clave API y estado del servicio |
| Respuestas incompletas | Contenido de entrada demasiado extenso | Reducir texto o implementar procesamiento por partes |
| Formatos incorrectos | Instrucciones de prompt insuficientes | Ajustar prompts para mayor especificidad |

## Pr√≥ximos Pasos y Mejoras

1. **Cach√© de respuestas**: Implementar almacenamiento para respuestas frecuentes
2. **Procesamiento por lotes**: Dividir documentos extensos para procesamiento paralelo
3. **APIs alternativas**: Soporte para m√∫ltiples proveedores de IA
4. **Autenticaci√≥n**: A√±adir capa de seguridad para control de acceso
5. **WebSockets**: Implementar actualizaciones en tiempo real durante procesamiento

---

Para m√°s informaci√≥n sobre la arquitectura general del proyecto, consultar el [README principal](../README.md).